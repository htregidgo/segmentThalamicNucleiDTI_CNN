import numpy as np
import os,sys
sys.path.append("..")

from joint_diffusion_structural_seg.predict import predict
from joint_diffusion_structural_seg.metrics import DiceLossLabels
from joint_diffusion_structural_seg import utils



def dice(vol_pred,vol_gt,level):
    vol_pred_flat = vol_pred.flatten()
    vol_gt_flat = vol_gt.flatten()

    vol_pred_flat[vol_pred_flat != level] = 0
    vol_pred_flat[vol_pred_flat == level] = 1
    vol_gt_flat[vol_gt_flat != level] = 0
    vol_gt_flat[vol_gt_flat == level] = 1

    inter = np.sum(y_true_f * y_pred_f)
    epsilon = 1e-5

    return (2. * inter + epsilon)/(np.sum(vol_gt_flat) + np.sum(vol_pred_flat) + epsilon)


def label_dice(label_list, vol_pred, vol_gt):
    dice_label_list = []
    for label in label_list:
        dice_label_list.append(dice(vol_pred,vol_gt,label))
    return dice_label_list


def group_dice(vol_pred, vol_gt): 



def thalamus_dice():
    




subject_list = ['subject_141119']
fs_subject_dir = '/autofs/space/nicc_003/users/olchanyi/scripts/tmp/files4mark/data/training_reduced/validate/'
# for now...must be
dataset = 'validate'
path_label_list = '/autofs/space/nicc_003/users/olchanyi/scripts/tmp/files4mark/data/proc_training_data_label_list_reduced.npy'
group_list = '/autofs/space/nicc_003/users/olchanyi/scripts/tmp/files4mark/data/proc_training_group_seg_reduced.npy'
model_file = '/autofs/space/nicc_003/users/olchanyi/scripts/tmp/files4mark/models/dice_200.h5'
# model file resolution
resolution_model_file=0.7
# generator mode for prediction data (make sure same as training!)
generator_mode='rgb'
# U-net: number of features in base level (make sure same as training!)
unet_feat_count=24
# U-net: number of levels (make sure same as training!)
n_levels = 5
# U-net: convolution kernel size (make sure same as training!)
conv_size = 3
# U-net: number of features per level multiplier (make sure same as training!)
feat_multiplier = 2
# U-net: number of convolutions per level (make sure same as training!)
nb_conv_per_level = 2
# U-net: activation function (make sure same as training!)
activation='elu'
# (isotropic) dimensions of bounding box to take around thalamus
bounding_box_width = 128
# reference affine
aff_ref = np.eye(4)


## load params including label and group lists
shell_mag = ['_1k','_2k']
seg_list = ['_1k_DSWbeta','_1k_LogGauss','_1k_Wishart','_2k_DSWbeta','_2k_LogGauss','_2k_Wishart']
label_list = np.load(path_label_list)
group_list = np.load(group_list)



for subject in subject_list:
    for shell in shell_mag:
        unet_seg_file = os.path.join(fs_subject_dir)

        predict([subject + shell],
                    fs_subject_dir,
                    dataset,
                    path_label_list,
                    model_file,
                    resolution_model_file,
                    generator_mode,
                    unet_feat_count,
                    n_levels,
                    conv_size,
                    feat_multiplier,
                    nb_conv_per_level,
                    activation,
                    bounding_box_width,
                    aff_ref,
                    shell_flag=shell)

        unet_seg_path = os.path.join(fs_subject_dir,subject + shell,'results','thalNet_reduced_randV1_e050.seg.mgz')
        t1_path = os.path.join(fs_subject_dir,subject + shell, subject + '.t1.nii.gz')

        # this is to make same dims
        os.system("mri_convert " + unet_seg_path + " " + unet_seg_path +  " -rl " +  t1_path + "  -rt nearest -odt float")
        unet_seg = utils.load_volume(unet_seg_path)
        dl = DiceLossLabels()
        for seg in seg_list:
            seg_path = os.path.join(fs_subject_dir,subject + shell,'segs',subject + seg + ".nii.gz")
            seg = utils.load_volume(seg_path)
            dice = dl.loss(unet_seg,seg)
            print("loss for " + seg + " in " + subject + " is: " + dice)
